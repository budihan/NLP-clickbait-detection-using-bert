{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertModel, BertConfig, BertTokenizer, BertForSequenceClassification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"data/webis17/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Webis Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    '''\n",
    "    self.corpus: (post, text, truthMean)\n",
    "    '''\n",
    "    def __init__(self, path):\n",
    "        self.train_file = path + 'input/instances.jsonl'\n",
    "        self.truth_file = path + 'input/truth.jsonl'\n",
    "        df_train = pd.read_json(self.train_file, lines=True)\n",
    "        df_truth = pd.read_json(self.truth_file, lines=True)\n",
    "        self.size = df_train.shape[0]\n",
    "\n",
    "        truth_id, truth_mean = list(df_truth['id']), list(df_truth['truthMean'])\n",
    "        truth_dict = {truth_id[i]:truth_mean[i] for i in range(self.size)}\n",
    "        train_id, train_post, train_text = list(df_train['id']), list(df_train['postText']), list(df_train['targetParagraphs'])\n",
    "        #? train_post[i] is a list\n",
    "        self.corpus = [(train_post[i][0], ' '.join(para for para in train_text[i]), truth_dict[train_id[i]]) for i in range(self.size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "bert_tokenizer.save_pretrained(dir+'bert-base-uncased')\n",
    "bert_model.save_pretrained(dir+'bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset class\n",
    "data = Dataset(dir)\n",
    "\n",
    "# extract data\n",
    "title_all = [data[0] for data in data.corpus]\n",
    "content_all = [data[1] for data in data.corpus]\n",
    "score_all = torch.tensor([data[2] for data in data.corpus], requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(score_all, dir+'scores.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average # of tokens = 17.628058143105743\n",
      "max # of tokens = 104\n",
      "torch.Size([19538, 20])\n",
      "tensor([[  101,  2866,  1521,  ...,  2489,   102,     0],\n",
      "        [  101,  2023,  2003,  ...,     0,     0,     0],\n",
      "        [  101,  1996,  1000,  ...,  1996,  2047,   102],\n",
      "        ...,\n",
      "        [  101,  2413,  2015,  ...,  2112,  1997,   102],\n",
      "        [  101,  2821,  5076,  ...,     0,     0,     0],\n",
      "        [  101,  2957, 11011,  ...,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "# title profiling\n",
    "title_all_tokenized_raw = bert_tokenizer(title_all,return_token_type_ids=False, return_attention_mask=False)['input_ids']\n",
    "\n",
    "print(f\"Average # of tokens = {np.mean([len(lst) for lst in title_all_tokenized_raw])}\")\n",
    "print(f\"max # of tokens = {max([len(lst) for lst in title_all_tokenized_raw])}\")\n",
    "\n",
    "title_all_tokenized = bert_tokenizer(title_all, padding=True,truncation=True,max_length=20, return_token_type_ids=False, return_attention_mask=False, return_tensors=\"pt\")['input_ids']\n",
    "print(title_all_tokenized.shape)\n",
    "print(title_all_tokenized)\n",
    "\n",
    "# Save tensors\n",
    "torch.save(title_all_tokenized, dir+'titles_tokens.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19538, 20])\n"
     ]
    }
   ],
   "source": [
    "title_all_tokenized = torch.load(dir+'titles_tokens.pt')\n",
    "print(title_all_tokenized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "\n",
    "# num_data = 19538\n",
    "# extract_size = 800\n",
    "# for i in range(num_data//800):\n",
    "#     outputs = bert_model(title_all_tokenized[(extract_size*i):(extract_size*(i+1)), :])\n",
    "#     title_all_embed = outputs[0]  # The last hidden-state is the first element of the output tuple\n",
    "#     print(title_all_embed.shape) # batchsize x # tokens of sent x embed_dim\n",
    "#     print(f\"From size {str(extract_size*i)} to {str(extract_size*(i+1))}\")\n",
    "    \n",
    "#     # save Data\n",
    "#     torch.save(title_all_embed, dir+'/embeddings/titles_'+str(extract_size*i)+'_'+str(extract_size*(i+1)))\n",
    "#     del outputs\n",
    "#     del title_all_embed\n",
    "#     gc.collect()\n",
    "\n",
    "# last portion\n",
    "\n",
    "# num_patchs = num_data//extract_size\n",
    "# outputs = bert_model(title_all_tokenized[(extract_size*num_patchs):, :])\n",
    "# title_all_embed = outputs[0] \n",
    "# print(title_all_embed.shape) \n",
    "# print(f\"From size {str(extract_size*num_patchs)} to {str(num_data)}\")\n",
    "\n",
    "# # save Data\n",
    "# torch.save(title_all_embed, dir+'/embeddings/titles_'+str(extract_size*num_patchs)+'_'+str(num_data))\n",
    "# del outputs\n",
    "# del title_all_embed\n",
    "# gc.collect()\n",
    "\n",
    "# Combine batches\n",
    "\n",
    "# Xt = torch.zeros(num_data, 20, 768)\n",
    "# for i in range(num_data//800):\n",
    "#     Xt[extract_size*i:extract_size*(i+1), :,: ] = torch.load(dir+'/embeddings/titles_'+str(extract_size*i)+'_'+str(extract_size*(i+1)))\n",
    "# Xt[extract_size*num_patchs:,:,:] = torch.load(dir+'/embeddings/titles_'+str(extract_size*num_patchs)+'_'+str(num_data))\n",
    "\n",
    "# print(Xt.shape)\n",
    "\n",
    "# # Save\n",
    "# torch.save(Xt, dir+'/titles_all.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 20, 768])\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "# Load CLS data\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "dir = \"data/webis17/\"\n",
    "\n",
    "Xt_all = torch.load(dir+'/titles_all.pt')[0:1000]\n",
    "yt_all = torch.load(dir+'/scores.pt')[0:1000]\n",
    "print(Xt_all.shape)\n",
    "print(yt_all.shape)\n",
    "\n",
    "num_data = 1000\n",
    "train_size = 800\n",
    "# val_size = 2000\n",
    "# test_size = num_data - train_size - val_size\n",
    "test_size = num_data - train_size\n",
    "batch_size = 64\n",
    "train_set = TensorDataset(Xt_all[:train_size,0,:], yt_all[:train_size])\n",
    "# val_set = TensorDataset(Xt_all[train_size:train_size+val_size,0,:], yt_all[train_size:train_size+val_size])\n",
    "test_set = TensorDataset(Xt_all[train_size:,0,:], yt_all[train_size:])\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=batch_size)\n",
    "# val_dataloader = DataLoader(val_set, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Simple LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, batch_size, num_tokens, embed_dim, hidden_dim,  n_layers = 1, dropout = 0.0):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.lstm=nn.LSTM(embed_dim, hidden_dim, n_layers, batch_first=True, dropout=dropout, bidirectional=True)\n",
    "        self.flatten = nn.Flatten(1)\n",
    "        # self.fc1=nn.Linear(num_tokens*hidden_dim, 64)\n",
    "        # self.fc1=nn.Linear(num_tokens*hidden_dim, 1)\n",
    "        # take CLS token, birection\n",
    "        self.fc1=nn.Linear(2*hidden_dim, 64)\n",
    "\n",
    "        self.fc2=nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        '''\n",
    "            x: batch_size x num_tokens x embed_dim\n",
    "        '''\n",
    "        # take CLS token\n",
    "        # print(x[:,0,:].unsqueeze(1).shape)\n",
    "        lstm_out, hidden = self.lstm(x.unsqueeze(1), hidden) # batch_size x 1 x (2*hidden_dim)\n",
    "\n",
    "        # flat = self.flatten(lstm_out) \n",
    "        flat = lstm_out.squeeze() # batch_size x hidden_dim\n",
    "\n",
    "        out1 = self.fc1(flat) # batch_size x 64\n",
    "        out2 = self.fc2(torch.relu(out1)) # batch_size x 1\n",
    "        out = torch.sigmoid(out2)\n",
    "\n",
    "        # # single layer\n",
    "        # out = torch.sigmoid(out1)\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        # birections -> *2\n",
    "        hidden = (weight.new(self.n_layers*2, batch_size, self.hidden_dim).zero_().to(device),\n",
    "                      weight.new(self.n_layers*2, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        return hidden\n",
    "\n",
    "    def init_weights(m):\n",
    "        '''\n",
    "        Initialize weights\n",
    "        '''\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NVIDIA GeForce RTX 2070 SUPER\n"
     ]
    }
   ],
   "source": [
    "# load GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method LSTM.init_weights of LSTM(\n",
       "  (lstm): LSTM(768, 10, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=20, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_dim = 10 # num of tokens is typically 20\n",
    "_ , num_tokens, embed_dim = Xt_all.shape\n",
    "# dropout = 0.0\n",
    "dropout = 0.2\n",
    "\n",
    "model = LSTM(batch_size, num_tokens, embed_dim, hidden_dim, n_layers=2, dropout = dropout).to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau # learning rate scheduler\n",
    "lr_scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.25, patience=0, threshold=0.05,min_lr=3e-5, verbose=True)\n",
    "\n",
    "model.init_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "### Training ###\n",
    "def train(train_dataloader, y_truth, model, loss_fn, optimizer, mute = False):\n",
    "    model.train()\n",
    "\n",
    "    size = len(train_dataloader.dataset)\n",
    "\n",
    "    y_pred_train = []\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        hidden = model.init_hidden(X.shape[0])\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred, hidden = model(X, hidden)\n",
    "        y_pred_train.extend(pred.squeeze().cpu())\n",
    "        loss = loss_fn(pred.squeeze(), y)\n",
    "        # Backpropagation\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 20 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            if not mute:\n",
    "                print(f\"Training loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    y_pred_train = torch.tensor(y_pred_train, dtype=float)\n",
    "    performance = loss_fn(y_pred_train, y_truth)\n",
    "    clf_performance = ((y_pred_train>0.5)==(y_truth>0.5)).float().mean()\n",
    "\n",
    "    if not mute:\n",
    "        print(f\"Training Loss: {performance}\")\n",
    "        print(f\"Training Classifier Accuracy: {clf_performance}\")\n",
    "    return y_pred_train\n",
    "\n",
    "### Testing ###\n",
    "def test(test_dataloader, y_truth, model, loss_fn, lr_scheduler, mute = False):\n",
    "    hidden_val = model.init_hidden(batch_size)\n",
    "    model.eval()\n",
    "\n",
    "    y_pred_val = []\n",
    "    for batch, (X, y) in enumerate(test_dataloader):\n",
    "        hidden_val = model.init_hidden(X.shape[0])\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred, hidden_val = model(X, hidden_val)\n",
    "        y_pred_val.extend(pred.squeeze().cpu())\n",
    "\n",
    "    y_pred_val = torch.tensor(y_pred_val, dtype=float)\n",
    "    performance = loss_fn(y_pred_val, y_truth)\n",
    " \n",
    "    clf_performance = ((y_pred_val>0.5)==(y_truth>0.5)).float().mean()\n",
    "\n",
    "    pre_performance = precision_score((y_truth>0.5).float().numpy(), (y_pred_val>0.5).float().numpy())\n",
    "    rec_performance = recall_score((y_truth>0.5).float().numpy(), (y_pred_val>0.5).float().numpy())\n",
    "\n",
    "    f1_performance = f1_score((y_pred_val>0.5).float().numpy(), (y_truth>0.5).float().numpy())\n",
    "    p_performance = pearsonr(y_pred_val.detach().numpy(), y_truth.detach().numpy())[0]\n",
    "    if not mute:\n",
    "        print(f\"Test Precision: {pre_performance}\")\n",
    "        print(f\"Test Recall: {rec_performance}\")\n",
    "        print(f\"Test Accuracy: {clf_performance}\")\n",
    "        print(f\"Test F1 Score: {f1_performance}\")\n",
    "        print(f\"Test Pearson Coefficient: {p_performance}\")\n",
    "\n",
    "    return performance  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training & validation\n",
    "\n",
    "# epochs = 50\n",
    "epochs = 20\n",
    "\n",
    "model.train()\n",
    "\n",
    "best_test_performance = 1.0 # any number works\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, yt_all[:train_size], model, loss_fn, optimizer)\n",
    "    test_performance = test(test_dataloader, yt_all[train_size:train_size+test_size], model, loss_fn, lr_scheduler)\n",
    "\n",
    "    if test_performance < best_test_performance:\n",
    "        best_test_performance = test_performance\n",
    "        print(f'NEW BEST MODEL! Performance: {best_test_performance}')\n",
    "        torch.save(model, dir+'/best_model')\n",
    "print(\"Done!\")\n",
    "\n",
    "torch.save(model, dir+'model_CLS_10_bi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "dir = 'data/webis17/'\n",
    "\n",
    "hidden_dim = 10 # num of tokens is typically 20\n",
    "_ , num_tokens, embed_dim = Xt_all.shape\n",
    "# dropout = 0.0\n",
    "dropout = 0.2\n",
    "\n",
    "model = LSTM(batch_size, num_tokens, embed_dim, hidden_dim, n_layers=2, dropout = dropout).to(device)\n",
    "model = torch.load(dir+'/best_model')\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau # learning rate scheduler\n",
    "lr_scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.25, patience=0, threshold=0.05,min_lr=3e-5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision: 0.92\n",
      "Test Recall: 0.48936170212765956\n",
      "Test Accuracy: 0.8700000047683716\n",
      "Test F1 Score: 0.6388888888888888\n",
      "Test Pearson Coefficient: 0.684032037329564\n"
     ]
    }
   ],
   "source": [
    "_ = test(test_dataloader, yt_all[train_size:], model, loss_fn, lr_scheduler)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2aa17256a3c0b2dacbf97c63a5a958f79060bfb41a7857c78a3e5de75c12b916"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
