{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertModel, BertConfig, BertTokenizer, BertForSequenceClassification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"data/webis17/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Webis Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    '''\n",
    "    self.corpus: (post, text, truthMean)\n",
    "    '''\n",
    "    def __init__(self, path):\n",
    "        self.train_file = path + 'input/instances.jsonl'\n",
    "        self.truth_file = path + 'input/truth.jsonl'\n",
    "        df_train = pd.read_json(self.train_file, lines=True)\n",
    "        df_truth = pd.read_json(self.truth_file, lines=True)\n",
    "        self.size = df_train.shape[0]\n",
    "\n",
    "        truth_id, truth_mean = list(df_truth['id']), list(df_truth['truthMean'])\n",
    "        truth_dict = {truth_id[i]:truth_mean[i] for i in range(self.size)}\n",
    "        train_id, train_post, train_text = list(df_train['id']), list(df_train['postText']), list(df_train['targetParagraphs'])\n",
    "        #? train_post[i] is a list\n",
    "        self.corpus = [(train_post[i][0], ' '.join(para for para in train_text[i]), truth_dict[train_id[i]]) for i in range(self.size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "bert_tokenizer.save_pretrained(dir+'bert-base-uncased')\n",
    "bert_model.save_pretrained(dir+'bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average # of tokens = 17.628058143105743\n",
      "max # of tokens = 104\n",
      "torch.Size([19538, 25])\n",
      "tensor([[  101,  2866,  1521,  ...,     0,     0,     0],\n",
      "        [  101,  2023,  2003,  ...,     0,     0,     0],\n",
      "        [  101,  1996,  1000,  ...,   102,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2413,  2015,  ...,  2803,  2933,   102],\n",
      "        [  101,  2821,  5076,  ...,     0,     0,     0],\n",
      "        [  101,  2957, 11011,  ...,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "# Create dataset class\n",
    "data = Dataset(dir)\n",
    "\n",
    "# extract data\n",
    "title_all = [data[0] for data in data.corpus]\n",
    "content_all = [data[1] for data in data.corpus]\n",
    "score_all = torch.tensor([data[2] for data in data.corpus], requires_grad=True)\n",
    "\n",
    "# title profiling\n",
    "title_all_tokenized_raw = bert_tokenizer(title_all,return_token_type_ids=False, return_attention_mask=False)['input_ids']\n",
    "\n",
    "print(f\"Average # of tokens = {np.mean([len(lst) for lst in title_all_tokenized_raw])}\")\n",
    "print(f\"max # of tokens = {max([len(lst) for lst in title_all_tokenized_raw])}\")\n",
    "\n",
    "title_all_tokenized = bert_tokenizer(title_all, padding=True,truncation=True,max_length=25, return_token_type_ids=False, return_attention_mask=False, return_tensors=\"pt\")['input_ids']\n",
    "print(title_all_tokenized.shape)\n",
    "print(title_all_tokenized)\n",
    "\n",
    "# Save tensors\n",
    "torch.save(title_all_tokenized, dir+'titles_tokens.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings and split train/val/test\n",
    "\n",
    "# train_size = 900\n",
    "# val_size = 100\n",
    "# outputs = bert_model(title_all_tokenized[:(train_size+val_size), :])\n",
    "# title_all_embed = outputs[0]  # The last hidden-state is the first element of the output tuple\n",
    "# print(title_all_embed.shape) # batchsize x # tokens of sent x embed_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_all_tokenized = torch.load(dir+'titles_tokens.pt')\n",
    "print(title_all_tokenized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "num_data = 19538\n",
    "extract_size = 1000\n",
    "for i in range(num_data//1000):\n",
    "    outputs = bert_model(title_all_tokenized[(extract_size*i):(extract_size*(i+1)), :])\n",
    "    title_all_embed = outputs[0]  # The last hidden-state is the first element of the output tuple\n",
    "    print(title_all_embed.shape) # batchsize x # tokens of sent x embed_dim\n",
    "    print(f\"From size {str(extract_size*i)} to {str(extract_size*(i+1))}\")\n",
    "    \n",
    "    # save Data\n",
    "    torch.save(title_all_embed, dir+'/titles_'+str(extract_size*i)+'_'+str(extract_size*(i+1)))\n",
    "    del outputs\n",
    "    del title_all_embed\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last portion\n",
    "\n",
    "num_patchs = num_data//extract_size\n",
    "outputs = bert_model(title_all_tokenized[(extract_size*num_patchs):, :])\n",
    "title_all_embed = outputs[0] \n",
    "print(title_all_embed.shape) \n",
    "print(f\"From size {str(extract_size*num_patchs)} to {str(num_data)}\")\n",
    "\n",
    "# save Data\n",
    "torch.save(title_all_embed, dir+'/titles_'+str(extract_size*num_patchs)+'_'+str(num_data))\n",
    "del outputs\n",
    "del title_all_embed\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine batches\n",
    "\n",
    "Xt = torch.zeros(num_data, 20, 768)\n",
    "for i in range(num_data//800):\n",
    "    # curr_Xt = torch.load(dir+'/titles_'+str(extract_size*i)+'_'+str(extract_size*(i+1)))\n",
    "    Xt[extract_size*i:extract_size*(i+1), :,: ] = torch.load(dir+'/titles_'+str(extract_size*i)+'_'+str(extract_size*(i+1)))\n",
    "Xt[extract_size*num_patchs:,:,:] = torch.load(dir+'/titles_'+str(extract_size*num_patchs)+'_'+str(num_data))\n",
    "\n",
    "print(Xt.shape)\n",
    "\n",
    "# Save\n",
    "torch.save(Xt, dir+'/titles_all.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CLS data\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "dir = '/content/drive/Shareddrives/EECS 498-004 NLP Project - Clickbait/data/clickbait17/'\n",
    "Xt_all = torch.load(dir+'/titles_all.pt')\n",
    "yt_all = torch.load(dir+'/scores.pt')\n",
    "print(Xt_all.shape)\n",
    "print(yt_all.shape)\n",
    "\n",
    "num_data = Xt_all.shape[0]\n",
    "train_size = 16000\n",
    "val_size = 2000\n",
    "test_size = num_data - train_size - val_size\n",
    "batch_size = 64\n",
    "train_set = TensorDataset(Xt_all[:train_size,0,:], yt_all[:train_size])\n",
    "val_set = TensorDataset(Xt_all[train_size:train_size+val_size,0,:], yt_all[train_size:train_size+val_size])\n",
    "test_set = TensorDataset(Xt_all[train_size+val_size:,0,:], yt_all[train_size+val_size:])\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=batch_size)\n",
    "val_dataloader = DataLoader(val_set, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Simple LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, batch_size, num_tokens, embed_dim, hidden_dim,  n_layers = 1, dropout = 0.0):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.lstm=nn.LSTM(embed_dim, hidden_dim, n_layers, batch_first=True, dropout=dropout, bidirectional=True)\n",
    "        self.flatten = nn.Flatten(1)\n",
    "        # self.fc1=nn.Linear(num_tokens*hidden_dim, 64)\n",
    "        # self.fc1=nn.Linear(num_tokens*hidden_dim, 1)\n",
    "        # take CLS token, birection\n",
    "        self.fc1=nn.Linear(2*hidden_dim, 64)\n",
    "\n",
    "        self.fc2=nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        '''\n",
    "            x: batch_size x num_tokens x embed_dim\n",
    "        '''\n",
    "        # take CLS token\n",
    "        # print(x[:,0,:].unsqueeze(1).shape)\n",
    "        lstm_out, hidden = self.lstm(x.unsqueeze(1), hidden) # batch_size x 1 x (2*hidden_dim)\n",
    "\n",
    "        # flat = self.flatten(lstm_out) \n",
    "        flat = lstm_out.squeeze() # batch_size x hidden_dim\n",
    "\n",
    "        out1 = self.fc1(flat) # batch_size x 64\n",
    "        out2 = self.fc2(torch.relu(out1)) # batch_size x 1\n",
    "        out = torch.sigmoid(out2)\n",
    "\n",
    "        # # single layer\n",
    "        # out = torch.sigmoid(out1)\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        # birections -> *2\n",
    "        hidden = (weight.new(self.n_layers*2, batch_size, self.hidden_dim).zero_().to(device),\n",
    "                      weight.new(self.n_layers*2, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        return hidden\n",
    "\n",
    "    def init_weights(m):\n",
    "        '''\n",
    "        Initialize weights\n",
    "        '''\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xt_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16012/1012581013.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mhidden_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;31m# num of tokens is typically 20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0m_\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mnum_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membed_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXt_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# dropout = 0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdropout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Xt_all' is not defined"
     ]
    }
   ],
   "source": [
    "hidden_dim = 10 # num of tokens is typically 20\n",
    "_ , num_tokens, embed_dim = Xt_all.shape\n",
    "# dropout = 0.0\n",
    "dropout = 0.2\n",
    "\n",
    "model = LSTM(batch_size, num_tokens, embed_dim, hidden_dim, n_layers=2, dropout = dropout).to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau # learning rate scheduler\n",
    "lr_scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.25, patience=0, threshold=0.05,min_lr=3e-5, verbose=True)\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing (helper functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training ###\n",
    "def train(train_dataloader, y_truth, model, loss_fn, optimizer, mute = False):\n",
    "    model.train()\n",
    "\n",
    "    size = len(train_dataloader.dataset)\n",
    "\n",
    "    y_pred_train = []\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        hidden = model.init_hidden(X.shape[0])\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred, hidden = model(X, hidden)\n",
    "        y_pred_train.extend(pred.squeeze().cpu())\n",
    "        loss = loss_fn(pred.squeeze(), y)\n",
    "        # Backpropagation\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 20 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            if not mute:\n",
    "                print(f\"Training loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    y_pred_train = torch.tensor(y_pred_train, dtype=float)\n",
    "    performance = loss_fn(y_pred_train, y_truth)\n",
    "    clf_performance = ((y_pred_train>0.5)==(y_truth>0.5)).float().mean()\n",
    "\n",
    "    if not mute:\n",
    "        print(f\"Training Loss: {performance}\")\n",
    "        print(f\"Training Classifier Accuracy: {clf_performance}\")\n",
    "    return y_pred_train\n",
    "\n",
    "### Testing ###\n",
    "def test(val_dataloader, y_truth, model, loss_fn, lr_scheduler, mute = False, mode = 0):\n",
    "    '''\n",
    "    mode = 0: validation when training (lr_scheduler)\n",
    "    mode = 1: validation\n",
    "    mode = 2: test\n",
    "    '''\n",
    "    hidden_val = model.init_hidden(batch_size)\n",
    "    model.eval()\n",
    "\n",
    "    y_pred_val = []\n",
    "    for batch, (X, y) in enumerate(val_dataloader):\n",
    "        hidden_val = model.init_hidden(X.shape[0])\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred, hidden_val = model(X, hidden_val)\n",
    "        y_pred_val.extend(pred.squeeze().cpu())\n",
    "\n",
    "    y_pred_val = torch.tensor(y_pred_val, dtype=float)\n",
    "    performance = loss_fn(y_pred_val, y_truth)\n",
    "    if mode == 0:\n",
    "        lr_scheduler.step(performance)\n",
    "    clf_performance = ((y_pred_val>0.5)==(y_truth>0.5)).float().mean()\n",
    "\n",
    "    f1_performance = f1_score((y_pred_val>0.5).float().numpy(), (y_truth>0.5).float().numpy())\n",
    "    p_performance = pearsonr(y_pred_val.detach().numpy(), y_truth.detach().numpy())[0]\n",
    "    if not mute:\n",
    "        if mode == 2:\n",
    "            print(f\"Test Loss: {performance}\")\n",
    "            print(f\"Test Accuracy: {clf_performance}\")\n",
    "            print(f\"Test F1 Score: {f1_performance}\")\n",
    "            print(f\"Test Pearson Coefficient: {p_performance}\")\n",
    "        else:\n",
    "            print(f\"Validation Loss: {performance}\")\n",
    "            print(f\"Validation Accuracy: {clf_performance}\")\n",
    "            print(f\"Validation F1 Score: {f1_performance}\")\n",
    "            print(f\"Test Pearson Coefficient: {p_performance}\")\n",
    "\n",
    "    return performance  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16012/898283348.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mbest_val_performance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;31m# any number works\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "## Training & validation\n",
    "\n",
    "# epochs = 50\n",
    "epochs = 1\n",
    "\n",
    "model.train()\n",
    "\n",
    "best_val_performance = 1.0 # any number works\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, yt_all[:train_size], model, loss_fn, optimizer)\n",
    "    val_performance = test(val_dataloader, yt_all[train_size:train_size+val_size], model, loss_fn, lr_scheduler)\n",
    "\n",
    "    if val_performance < best_val_performance:\n",
    "        best_val_performance = val_performance\n",
    "        print(f'NEW BEST MODEL! Performance: {best_val_performance}')\n",
    "        torch.save(model, dir+'/best_model')\n",
    "print(\"Done!\")\n",
    "\n",
    "torch.save(model, dir+'model_CLS_10_bi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "dir = '/content/drive/Shareddrives/EECS 498-004 NLP Project - Clickbait/data/clickbait17/'\n",
    "\n",
    "hidden_dim = 10 # num of tokens is typically 20\n",
    "_ , num_tokens, embed_dim = Xt_all.shape\n",
    "# dropout = 0.0\n",
    "dropout = 0.2\n",
    "\n",
    "model = LSTM(batch_size, num_tokens, embed_dim, hidden_dim, n_layers=2, dropout = dropout).to(device)\n",
    "model = torch.load(dir+'/best_model')\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau # learning rate scheduler\n",
    "lr_scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.25, patience=0, threshold=0.05,min_lr=3e-5, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2aa17256a3c0b2dacbf97c63a5a958f79060bfb41a7857c78a3e5de75c12b916"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
